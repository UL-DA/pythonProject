{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f752754-4e48-4647-a3b5-ff2044a25af3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3d547-3910-4de8-bd3b-b3a4a7b64617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                    | 0/20293 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import psycopg2\n",
    "import datetime\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "\n",
    "### 1. 법정동 API\n",
    "lawd_cd_df = pd.DataFrame()\n",
    "lawd_cd_list = []\n",
    "lawd_cd_unique = []\n",
    "\n",
    "for i in range(1, 22):\n",
    "    \n",
    "    url = 'http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList'\n",
    "    serviceKey = 'C94PKnigawlH2iISVWz1Itw9tVzyuOCbOvKgzCrGOUZWvs3XqrkhH+/ntypJ7kK2P2g16vLYCJif3TNfO1i1KA=='\n",
    "    params = {\n",
    "        'serviceKey' : serviceKey,\n",
    "        'pageNo' : str(i),\n",
    "        'numOfRows' : '1000',\n",
    "        'type' : 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    content = response.text\n",
    "    \n",
    "    # Json List 변환\n",
    "    lawd_cd_df = pd.DataFrame(pd.json_normalize(data = json.loads(content), record_path = 'StanReginCd')['row'][1])\n",
    "    lawd_cd_list = list(lawd_cd_df['locatjumin_cd'].str[:10])\n",
    "    \n",
    "    # 시군구코드 unique하게 남기기\n",
    "    for x in lawd_cd_list:\n",
    "        if x not in lawd_cd_unique:\n",
    "            lawd_cd_unique.append(x)\n",
    "\n",
    "# 시군구 단위 삭제 (법정동 단위만 남김 : 총 20,293개)\n",
    "matching = [s for s in lawd_cd_unique if \"00000\" in s]\n",
    "for s in lawd_cd_unique:\n",
    "    if s in matching:\n",
    "        lawd_cd_unique.remove(s)\n",
    "\n",
    "\n",
    "### 2. 전월세 호가 수집\n",
    "# 변수 생성\n",
    "fails = [] # 호가 데이터 없는 법정동\n",
    "noColIdx = [] # 컬럼명 다른 지역 따로 처리\n",
    "\n",
    "# json to dataframe\n",
    "for i in tqdm(range(len(lawd_cd_unique))):\n",
    "    \n",
    "    # 초기화\n",
    "    info_df = pd.DataFrame()\n",
    "\n",
    "    # 전체 페이지 수집\n",
    "    for page in range(0,100):\n",
    "\n",
    "        # url 호출\n",
    "        url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank&page={}'.format(lawd_cd_unique[i],str(page+1))\n",
    "        headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "        time.sleep(random.randrange(3,7))\n",
    "        response = requests.get(url, headers = headers)\n",
    "\n",
    "        # body 태그 선택\n",
    "        items = response.json()['body']\n",
    "\n",
    "        # 다음 페이지 존재 여부 확인\n",
    "        if (len(items) > 0):\n",
    "            try:\n",
    "                # 데이터프레임화\n",
    "                df = pd.DataFrame(items)\n",
    "                info_df = info_df.append(df)\n",
    "            except:\n",
    "                fails.append([i])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 받은 데이터 바로 적재 (언제 막힐지 모르니까 바로바로 적재)\n",
    "    if len(info_df) > 0:\n",
    "        \n",
    "        # 컬럼명 다른 지역이 있음 (따로 처리)\n",
    "        try:\n",
    "            # 컬럼 정리\n",
    "            info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','cpid','cpNm','rltrNm']]\n",
    "            # None 처리\n",
    "            info_df = info_df.fillna(None)\n",
    "            \n",
    "            ### 3. DB INSERT\n",
    "            df = info_df\n",
    "            table = 'm1.asking_price'\n",
    "\n",
    "            # execute_mogrify\n",
    "            def execute_mogrify(conn, df, table, val):\n",
    "                # Create a list of tuples from the dataframe values\n",
    "                tuples = [tuple(x) for x in df.to_numpy()]\n",
    "                # Comma-separated dataframe columns\n",
    "                cols = ','.join(list(df.columns))\n",
    "                # SQL query to execute\n",
    "                cursor = conn.cursor()\n",
    "                values = [cursor.mogrify(val, tup).decode('utf8') for tup in\n",
    "                          tuples]\n",
    "                query = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "\n",
    "                try:\n",
    "                    cursor.execute(query, tuples)\n",
    "                    conn.commit()\n",
    "                except (Exception, psycopg2.DatabaseError) as error:\n",
    "                    print(\"Error: %s\" % error)\n",
    "                    conn.rollback()\n",
    "                    cursor.close()\n",
    "                    return 1\n",
    "                cursor.close()\n",
    "\n",
    "            # values 설정\n",
    "            val = '(' + ('%s,' * len(df.columns))[:-1] + ')'\n",
    "\n",
    "            # insert\n",
    "            for j in range(0, len(df), 10000):\n",
    "\n",
    "                # DB Connect\n",
    "                conn = psycopg2.connect(\n",
    "                    host='redshift-cluster-1.ctvbwnnvbdkl.ap-northeast-2.redshift.amazonaws.com',\n",
    "                    port=5439,\n",
    "                    dbname='dev',\n",
    "                    user='awsuser',\n",
    "                    password='cremaoAdmin1234qwer!!'\n",
    "                )\n",
    "\n",
    "                # 10000개 단위로 나누기\n",
    "                tmp = df[j:j + 10000]\n",
    "\n",
    "                # insert\n",
    "                execute_mogrify(conn, tmp, table, val)\n",
    "                print(datetime.datetime.now(), ' : ', j)\n",
    "                tmp = pd.DataFrame()\n",
    "\n",
    "            # row count\n",
    "            print(len(df))\n",
    "            \n",
    "        except:\n",
    "            noColIdx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08301073-9538-4786-b1a2-39c5de8afba0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ver1 (csv불러오기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b193ff1-0521-4ede-95a7-07f1cf99c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import psycopg2\n",
    "import datetime\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "### 1. 깃에서 법정동 CSV 파일 불러오기 (법정동코드 10자리)\n",
    "cortar = pd.read_csv('C:\\\\oasis\\\\oasisbusiness-ds\\\\oasisbusiness-ds\\\\1_데이터수집\\\\법정동코드전체.csv')\n",
    "cortar = cortar[cortar['폐지여부\\r\\n']=='존재\\r\\n'] # 존재하는 지역만 남기기\n",
    "lawd_cd_unique = cortar.drop_duplicates('법정동코드')['법정동코드'] # 법정동 코드만 담기 (총 20551개)\n",
    "\n",
    "### 2. 전월세 호가 수집\n",
    "# 변수 생성\n",
    "fails = [] # 수집 안 된 법정동\n",
    "info_df = pd.DataFrame() # 최종 데이터프레임\n",
    "\n",
    "# json to dataframe (법정동 단위 수집)\n",
    "for i in tqdm(range(0,5000)):\n",
    "    \n",
    "    # url 설정\n",
    "    url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank'.format(lawd_cd_unique[i])\n",
    "      \n",
    "    try:\n",
    "        # url 호출\n",
    "        headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "        time.sleep(random.randrange(3,7))\n",
    "        response = requests.get(url, headers = headers)\n",
    "\n",
    "        # body 태그 선택\n",
    "        items = response.json()['body']\n",
    "\n",
    "        # 데이터프레임화\n",
    "        df = pd.DataFrame(items)\n",
    "        info_df = info_df.append(df)\n",
    "        time.sleep(random.randrange(1,7))\n",
    "\n",
    "    except:\n",
    "        fails.append([i])\n",
    "    \n",
    "    # 받아온 바로 적재 (언제 막힐지 모르니까 바로바로 적재함)\n",
    "    if len(info_df) > 0:\n",
    "        \n",
    "        # 컬럼 정리\n",
    "        info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','cpid','cpNm','rltrNm']]\n",
    "        # NaN 처리\n",
    "        info_df = info_df.fillna(np.nan)\n",
    "\n",
    "        ### 3. DB INSERT\n",
    "        df = info_df\n",
    "        table = 'm1.asking_price'\n",
    "\n",
    "        # execute_mogrify\n",
    "        def execute_mogrify(conn, df, table, val):\n",
    "            # Create a list of tuples from the dataframe values\n",
    "            tuples = [tuple(x) for x in df.to_numpy()]\n",
    "            # Comma-separated dataframe columns\n",
    "            cols = ','.join(list(df.columns))\n",
    "            # SQL query to execute\n",
    "            cursor = conn.cursor()\n",
    "            values = [cursor.mogrify(val, tup).decode('utf8') for tup in\n",
    "                      tuples]\n",
    "            query = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "\n",
    "            try:\n",
    "                cursor.execute(query, tuples)\n",
    "                conn.commit()\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                print(\"Error: %s\" % error)\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                return 1\n",
    "            cursor.close()\n",
    "\n",
    "        # values 설정\n",
    "        val = '(' + ('%s,' * len(df.columns))[:-1] + ')'\n",
    "\n",
    "        # insert\n",
    "        for j in range(0, len(df), 10000):\n",
    "\n",
    "            # DB Connect\n",
    "            conn = psycopg2.connect(\n",
    "                host='redshift-cluster-1.ctvbwnnvbdkl.ap-northeast-2.redshift.amazonaws.com',\n",
    "                port=5439,\n",
    "                dbname='dev',\n",
    "                user='awsuser',\n",
    "                password='cremaoAdmin1234qwer!!'\n",
    "            )\n",
    "\n",
    "            # 10000개 단위로 나누기\n",
    "            tmp = df[j:j + 10000]\n",
    "\n",
    "            # insert\n",
    "            execute_mogrify(conn, tmp, table, val)\n",
    "            print(datetime.datetime.now(), ' : ', j)\n",
    "            tmp = pd.DataFrame()\n",
    "\n",
    "        # row count\n",
    "        print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead5270-ff24-4cf5-8235-29aa062ee12b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ver2 (법정동 API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb4832-bd81-4944-9bbe-b16cb1ce51f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                     | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 5ms 1/3\n",
      "<Response [307]> 4ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 1/1000 [00:14<3:58:12, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 4ms 1/3\n",
      "<Response [307]> 6ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                          | 2/1000 [00:28<3:59:00, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 4ms 3/3\n",
      "<Response [307]> 6ms 1/3\n",
      "<Response [307]> 5ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                          | 3/1000 [00:44<4:06:20, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 4ms 3/3\n",
      "<Response [307]> 3ms 1/3\n",
      "<Response [307]> 5ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                          | 4/1000 [00:57<3:56:41, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 5ms 3/3\n",
      "<Response [307]> 4ms 1/3\n",
      "<Response [307]> 6ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                          | 5/1000 [01:12<3:58:28, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 4ms 3/3\n",
      "<Response [307]> 3ms 1/3\n",
      "<Response [307]> 6ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                          | 6/1000 [01:27<4:03:53, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 6ms 3/3\n",
      "<Response [307]> 3ms 1/3\n",
      "<Response [307]> 5ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                          | 7/1000 [01:41<4:02:05, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 6ms 3/3\n",
      "<Response [307]> 4ms 1/3\n",
      "<Response [307]> 4ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                                          | 8/1000 [01:54<3:50:02, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 4ms 3/3\n",
      "<Response [307]> 5ms 1/3\n",
      "<Response [307]> 4ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                          | 9/1000 [02:09<3:57:47, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 6ms 3/3\n",
      "<Response [307]> 3ms 1/3\n",
      "<Response [307]> 5ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                         | 10/1000 [02:21<3:42:30, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 3ms 3/3\n",
      "<Response [307]> 5ms 1/3\n",
      "<Response [307]> 6ms 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                        | 11/1000 [02:36<3:52:03, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [307]> 4ms 3/3\n"
     ]
    }
   ],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "### 1. 법정동 API\n",
    "lawd_cd_df = pd.DataFrame()\n",
    "lawd_cd_list = []\n",
    "lawd_cd_unique = []\n",
    "\n",
    "for i in range(1, 22):\n",
    "    \n",
    "    url = 'http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList'\n",
    "    serviceKey = 'C94PKnigawlH2iISVWz1Itw9tVzyuOCbOvKgzCrGOUZWvs3XqrkhH+/ntypJ7kK2P2g16vLYCJif3TNfO1i1KA=='\n",
    "    params = {\n",
    "        'serviceKey' : serviceKey,\n",
    "        'pageNo' : str(i),\n",
    "        'numOfRows' : '1000',\n",
    "        'type' : 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    content = response.text\n",
    "    \n",
    "    # Json List 변환\n",
    "    lawd_cd_df = pd.DataFrame(pd.json_normalize(data = json.loads(content), record_path = 'StanReginCd')['row'][1])\n",
    "    lawd_cd_list = list(lawd_cd_df['locatjumin_cd'].str[:10])\n",
    "    \n",
    "    # 시군구코드 unique하게 남기기\n",
    "    for x in lawd_cd_list:\n",
    "        if x not in lawd_cd_unique:\n",
    "            lawd_cd_unique.append(x)\n",
    "            \n",
    "            \n",
    "fails = []\n",
    "info_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0,1000)):\n",
    "    cortar_url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank'.format(lawd_cd_unique[i])\n",
    "    count = 0\n",
    "    \n",
    "    for num in range(1,4):\n",
    "        \n",
    "        try:\n",
    "            count += 1\n",
    "            start = time.time() \n",
    "            url = cortar_url + str(num)\n",
    "            headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "            time.sleep(random.randrange(3,7))\n",
    "            response = requests.get(url, headers = headers)\n",
    "            print(response,str(int(time.time()-start)) + 'ms', str(count) +'/3')\n",
    "            items = response.json()['body']\n",
    "            df = pd.DataFrame(items)\n",
    "            info_df = info_df.append(df)\n",
    "        except:\n",
    "            fails.append([i,num])\n",
    "            \n",
    "    if i % 100 == 0:\n",
    "        info_df.to_csv('./네이버부동산_'+str(i+2)+'.csv',index=False,encoding='utf-8-sig')\n",
    "\n",
    "info_df.to_csv('./네이버부동산_'+str(i+1)+'.csv',index=False,encoding='utf-8-sig')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5edb77-c234-45a2-8bcd-6e17b7f7a8ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ver3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a501f18-9b1e-4386-961f-fae28b824fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import psycopg2\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "\n",
    "### 1. 법정동 API\n",
    "lawd_cd_df = pd.DataFrame()\n",
    "lawd_cd_list = []\n",
    "lawd_cd_unique = []\n",
    "\n",
    "for i in range(1, 22):\n",
    "    \n",
    "    url = 'http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList'\n",
    "    serviceKey = 'C94PKnigawlH2iISVWz1Itw9tVzyuOCbOvKgzCrGOUZWvs3XqrkhH+/ntypJ7kK2P2g16vLYCJif3TNfO1i1KA=='\n",
    "    params = {\n",
    "        'serviceKey' : serviceKey,\n",
    "        'pageNo' : str(i),\n",
    "        'numOfRows' : '1000',\n",
    "        'type' : 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    content = response.text\n",
    "    \n",
    "    # Json List 변환\n",
    "    lawd_cd_df = pd.DataFrame(pd.json_normalize(data = json.loads(content), record_path = 'StanReginCd')['row'][1])\n",
    "    lawd_cd_list = list(lawd_cd_df['locatjumin_cd'].str[:10])\n",
    "    \n",
    "    # 시군구코드 unique하게 남기기\n",
    "    for x in lawd_cd_list:\n",
    "        if x not in lawd_cd_unique:\n",
    "            lawd_cd_unique.append(x)\n",
    "\n",
    "\n",
    "### 2. 전월세 호가 수집\n",
    "# 변수 생성\n",
    "fails = [] # 수집 안 된 법정동\n",
    "info_df = pd.DataFrame() # 최종 데이터프레임\n",
    "\n",
    "# json to dataframe (법정동 단위 수집)\n",
    "for i in tqdm(range(0,2)):\n",
    "    \n",
    "    # url 설정\n",
    "    url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank'.format(lawd_cd_unique[i])\n",
    "      \n",
    "    try:\n",
    "        # url 호출\n",
    "        headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "        time.sleep(random.randrange(3,7))\n",
    "        response = requests.get(url, headers = headers)\n",
    "\n",
    "        # body 태그 선택\n",
    "        items = response.json()['body']\n",
    "\n",
    "        # 데이터프레임화\n",
    "        df = pd.DataFrame(items)\n",
    "        info_df = info_df.append(df)\n",
    "        time.sleep(random.randrange(1,7))\n",
    "\n",
    "    except:\n",
    "        fails.append([i])\n",
    "    \n",
    "    # 받아온 바로 적재 (언제 막힐지 모르니까 바로바로 적재함)\n",
    "    if len(info_df) > 0:\n",
    "        \n",
    "        # 컬럼 정리\n",
    "        info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','cpid','cpNm','rltrNm']]\n",
    "        # NaN 처리\n",
    "        info_df = info_df.fillna(np.nan)\n",
    "\n",
    "        ### 3. DB INSERT\n",
    "        df = info_df\n",
    "        table = 'm1.asking_price'\n",
    "\n",
    "        # execute_mogrify\n",
    "        def execute_mogrify(conn, df, table, val):\n",
    "            # Create a list of tuples from the dataframe values\n",
    "            tuples = [tuple(x) for x in df.to_numpy()]\n",
    "            # Comma-separated dataframe columns\n",
    "            cols = ','.join(list(df.columns))\n",
    "            # SQL query to execute\n",
    "            cursor = conn.cursor()\n",
    "            values = [cursor.mogrify(val, tup).decode('utf8') for tup in\n",
    "                      tuples]\n",
    "            query = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "\n",
    "            try:\n",
    "                cursor.execute(query, tuples)\n",
    "                conn.commit()\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                print(\"Error: %s\" % error)\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                return 1\n",
    "            cursor.close()\n",
    "\n",
    "        # values 설정\n",
    "        val = '(' + ('%s,' * len(df.columns))[:-1] + ')'\n",
    "\n",
    "        # insert\n",
    "        for j in range(0, len(df), 10000):\n",
    "\n",
    "            # DB Connect\n",
    "            conn = psycopg2.connect(\n",
    "                host='redshift-cluster-1.ctvbwnnvbdkl.ap-northeast-2.redshift.amazonaws.com',\n",
    "                port=5439,\n",
    "                dbname='dev',\n",
    "                user='awsuser',\n",
    "                password='cremaoAdmin1234qwer!!'\n",
    "            )\n",
    "\n",
    "            # 10000개 단위로 나누기\n",
    "            tmp = df[j:j + 10000]\n",
    "\n",
    "            # insert\n",
    "            execute_mogrify(conn, tmp, table, val)\n",
    "            print(datetime.datetime.now(), ' : ', j)\n",
    "            tmp = pd.DataFrame()\n",
    "\n",
    "        # row count\n",
    "        print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c86d19-43e2-44c2-aa87-5ae95055d15e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import psycopg2\n",
    "import datetime\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "### 1. 깃에서 법정동 CSV 파일 불러오기 (법정동코드 10자리)\n",
    "cortar = pd.read_csv('C:\\\\oasis\\\\oasisbusiness-ds\\\\oasisbusiness-ds\\\\1_데이터수집\\\\법정동코드전체.csv')\n",
    "cortar = cortar[cortar['폐지여부\\r\\n']=='존재\\r\\n'] # 존재하는 지역만 남기기\n",
    "lawd_cd_unique = cortar.drop_duplicates('법정동코드')['법정동코드'] # 법정동 코드만 담기 (총 20551개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cf92d75-25d3-4415-8541-4282d437449e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-06 18:37:47.183221  :  0\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 2. 전월세 호가 수집\n",
    "# 변수 생성\n",
    "fails = [] # 수집 안 된 법정동\n",
    "info_df = pd.DataFrame() # 최종 데이터프레임\n",
    "\n",
    "# json to dataframe (법정동 단위 수집)\n",
    "for i in tqdm(range(0,2)):\n",
    "    \n",
    "    # url 설정\n",
    "    url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank'.format(lawd_cd_unique[i])\n",
    "      \n",
    "    try:\n",
    "        # url 호출\n",
    "        headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "        time.sleep(random.randrange(3,7))\n",
    "        response = requests.get(url, headers = headers)\n",
    "\n",
    "        # body 태그 선택\n",
    "        items = response.json()['body']\n",
    "\n",
    "        # 데이터프레임화\n",
    "        df = pd.DataFrame(items)\n",
    "        info_df = info_df.append(df)\n",
    "        time.sleep(random.randrange(1,7))\n",
    "\n",
    "    except:\n",
    "        fails.append([i])\n",
    "    \n",
    "    # 받아온 바로 적재 (언제 막힐지 모르니까 바로바로 적재함)\n",
    "    if len(info_df) > 0:\n",
    "        \n",
    "        # 컬럼 정리\n",
    "        info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','cpid','cpNm','rltrNm']]\n",
    "        # NaN 처리\n",
    "        info_df = info_df.fillna(np.nan)\n",
    "\n",
    "        ### 3. DB INSERT\n",
    "        df = info_df\n",
    "        table = 'm1.asking_price'\n",
    "\n",
    "        # execute_mogrify\n",
    "        def execute_mogrify(conn, df, table, val):\n",
    "            # Create a list of tuples from the dataframe values\n",
    "            tuples = [tuple(x) for x in df.to_numpy()]\n",
    "            # Comma-separated dataframe columns\n",
    "            cols = ','.join(list(df.columns))\n",
    "            # SQL query to execute\n",
    "            cursor = conn.cursor()\n",
    "            values = [cursor.mogrify(val, tup).decode('utf8') for tup in\n",
    "                      tuples]\n",
    "            query = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "\n",
    "            try:\n",
    "                cursor.execute(query, tuples)\n",
    "                conn.commit()\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                print(\"Error: %s\" % error)\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                return 1\n",
    "            cursor.close()\n",
    "\n",
    "        # values 설정\n",
    "        val = '(' + ('%s,' * len(df.columns))[:-1] + ')'\n",
    "\n",
    "        # insert\n",
    "        for j in range(0, len(df), 10000):\n",
    "\n",
    "            # DB Connect\n",
    "            conn = psycopg2.connect(\n",
    "                host='redshift-cluster-1.ctvbwnnvbdkl.ap-northeast-2.redshift.amazonaws.com',\n",
    "                port=5439,\n",
    "                dbname='dev',\n",
    "                user='awsuser',\n",
    "                password='cremaoAdmin1234qwer!!'\n",
    "            )\n",
    "\n",
    "            # 10000개 단위로 나누기\n",
    "            tmp = df[j:j + 10000]\n",
    "\n",
    "            # insert\n",
    "            execute_mogrify(conn, tmp, table, val)\n",
    "            print(datetime.datetime.now(), ' : ', j)\n",
    "            tmp = pd.DataFrame()\n",
    "\n",
    "        # row count\n",
    "        print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bb20f-13e2-465a-b69c-9041ed795e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 정리\n",
    "info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','cpid','cpNm','rltrNm']]\n",
    "# NaN 처리\n",
    "info_df = info_df.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bacd883-d3d5-4620-b4b0-3b88772c861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to str\n",
    "info_df = info_df.reset_index(drop=True)\n",
    "for i in info_df.index:\n",
    "    info_df.loc[i]['tagList'] = ' '.join(info_df['tagList'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81219ca-a8fb-4909-8d87-4d4eb4e3052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 정리\n",
    "info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','hanPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','tagList','bildNm','minute','sameAddrCnt','sameAddrDirectCnt','cpid','cpNm','cpCnt','rltrNm','directTradYn','minMviFee','maxMviFee','etRoomCnt','tradePriceHan','tradeRentPrice','tradeCheckedByOwner','cpLinkVO','dtlAddrYn','dtlAddr']]\n",
    "# info_df = info_df.reset_index(drop=True)\n",
    "\n",
    "# 매물정보(cpLinkVO) 데이터 타입 변경 (dict to list)\n",
    "for i in range(len(info_df.index)):\n",
    "    for key, value in info_df['cpLinkVO'].iteritems():\n",
    "        tmp = [value]\n",
    "        info_df['cpLinkVO'][i] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462928dc-0a06-43bb-88a5-aeeabba9ec8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-06 18:33:21.595011  :  0\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "### 3. DB INSERT\n",
    "df = info_df\n",
    "table = 'm1.asking_price'\n",
    "\n",
    "# execute_mogrify\n",
    "def execute_mogrify(conn, df, table, val):\n",
    "    # Create a list of tuples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    cursor = conn.cursor()\n",
    "    values = [cursor.mogrify(val, tup).decode('utf8') for tup in\n",
    "              tuples]\n",
    "    query = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    cursor.close()\n",
    "\n",
    "# values 설정\n",
    "val = '(' + ('%s,' * len(df.columns))[:-1] + ')'\n",
    "\n",
    "# insert\n",
    "for j in range(0, len(df), 10000):\n",
    "\n",
    "    # DB Connect\n",
    "    conn = psycopg2.connect(\n",
    "        host='redshift-cluster-1.ctvbwnnvbdkl.ap-northeast-2.redshift.amazonaws.com',\n",
    "        port=5439,\n",
    "        dbname='dev',\n",
    "        user='awsuser',\n",
    "        password='cremaoAdmin1234qwer!!'\n",
    "    )\n",
    "\n",
    "    # 10000개 단위로 나누기\n",
    "    tmp = df[j:j + 10000]\n",
    "\n",
    "    # insert\n",
    "    execute_mogrify(conn, tmp, table, val)\n",
    "    print(datetime.datetime.now(), ' : ', j)\n",
    "    tmp = pd.DataFrame()\n",
    "\n",
    "# row count\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea5663-a049-403f-bf73-b4b4be511ee8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ver4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad094f7-0895-4ea6-b0d8-bf241b16e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import psycopg2\n",
    "import datetime\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "\n",
    "### 1. 법정동 API\n",
    "lawd_cd_df = pd.DataFrame()\n",
    "lawd_cd_list = []\n",
    "lawd_cd_unique = []\n",
    "\n",
    "for i in range(1, 22):\n",
    "    \n",
    "    url = 'http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList'\n",
    "    serviceKey = 'C94PKnigawlH2iISVWz1Itw9tVzyuOCbOvKgzCrGOUZWvs3XqrkhH+/ntypJ7kK2P2g16vLYCJif3TNfO1i1KA=='\n",
    "    params = {\n",
    "        'serviceKey' : serviceKey,\n",
    "        'pageNo' : str(i),\n",
    "        'numOfRows' : '1000',\n",
    "        'type' : 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    content = response.text\n",
    "    \n",
    "    # Json List 변환\n",
    "    lawd_cd_df = pd.DataFrame(pd.json_normalize(data = json.loads(content), record_path = 'StanReginCd')['row'][1])\n",
    "    lawd_cd_list = list(lawd_cd_df['locatjumin_cd'].str[:10])\n",
    "    \n",
    "    # 시군구코드 unique하게 남기기\n",
    "    for x in lawd_cd_list:\n",
    "        if x not in lawd_cd_unique:\n",
    "            lawd_cd_unique.append(x)\n",
    "\n",
    "# 시군구 단위 삭제\n",
    "matching = [s for s in lawd_cd_unique if \"00000\" in s]\n",
    "for s in lawd_cd_unique:\n",
    "    if s in matching:\n",
    "        lawd_cd_unique.remove(s)\n",
    "\n",
    "\n",
    "### 2. 전월세 호가 수집\n",
    "# 변수 생성\n",
    "fails = [] # 호가 데이터 없는 법정동\n",
    "\n",
    "# json to dataframe\n",
    "for i in tqdm(range(len(lawd_cd_unique))):\n",
    "    \n",
    "    # 초기화\n",
    "    info_df = pd.DataFrame()\n",
    "\n",
    "    # 다음 페이지 존재 여부 확인\n",
    "    for page in tqdm(range(0,10000)): # 진행상황 확인하고 tqdm 지우기\n",
    "\n",
    "        # url 호출\n",
    "        url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank&page={}'.format(lawd_cd_unique[i],str(page+1))\n",
    "        headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "        time.sleep(random.randrange(3,7))\n",
    "        response = requests.get(url, headers = headers)\n",
    "\n",
    "        # body 태그 선택\n",
    "        items = response.json()['body']\n",
    "\n",
    "        # 다음 페이지 존재 여부 확인\n",
    "        if (response.json()['more'] == True):\n",
    "\n",
    "            try:\n",
    "                # 데이터프레임화\n",
    "                df = pd.DataFrame(items)\n",
    "                info_df = info_df.append(df)\n",
    "            except:\n",
    "                fails.append([i])\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 받은 데이터 바로 적재 (언제 막힐지 모르니까 바로바로 적재함)\n",
    "    if len(info_df) > 0:\n",
    "        \n",
    "        # 컬럼 정리\n",
    "        info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','cpid','cpNm','rltrNm']]\n",
    "        # NaN 처리\n",
    "        info_df = info_df.fillna(np.nan)\n",
    "\n",
    "        ### 3. DB INSERT\n",
    "        df = info_df\n",
    "        table = 'm1.asking_price'\n",
    "\n",
    "        # execute_mogrify\n",
    "        def execute_mogrify(conn, df, table, val):\n",
    "            # Create a list of tuples from the dataframe values\n",
    "            tuples = [tuple(x) for x in df.to_numpy()]\n",
    "            # Comma-separated dataframe columns\n",
    "            cols = ','.join(list(df.columns))\n",
    "            # SQL query to execute\n",
    "            cursor = conn.cursor()\n",
    "            values = [cursor.mogrify(val, tup).decode('utf8') for tup in\n",
    "                      tuples]\n",
    "            query = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "\n",
    "            try:\n",
    "                cursor.execute(query, tuples)\n",
    "                conn.commit()\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                print(\"Error: %s\" % error)\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                return 1\n",
    "            cursor.close()\n",
    "\n",
    "        # values 설정\n",
    "        val = '(' + ('%s,' * len(df.columns))[:-1] + ')'\n",
    "\n",
    "        # insert\n",
    "        for j in range(0, len(df), 10000):\n",
    "\n",
    "            # DB Connect\n",
    "            conn = psycopg2.connect(\n",
    "                host='redshift-cluster-1.ctvbwnnvbdkl.ap-northeast-2.redshift.amazonaws.com',\n",
    "                port=5439,\n",
    "                dbname='dev',\n",
    "                user='awsuser',\n",
    "                password='cremaoAdmin1234qwer!!'\n",
    "            )\n",
    "\n",
    "            # 10000개 단위로 나누기\n",
    "            tmp = df[j:j + 10000]\n",
    "\n",
    "            # insert\n",
    "            execute_mogrify(conn, tmp, table, val)\n",
    "            print(datetime.datetime.now(), ' : ', j)\n",
    "            tmp = pd.DataFrame()\n",
    "\n",
    "        # row count\n",
    "        print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22c4bde5-a434-4cb6-ba25-ae678a9055bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import psycopg2\n",
    "import datetime\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "### 1. 깃에서 법정동 CSV 파일 불러오기 (법정동코드 10자리)\n",
    "cortar = pd.read_csv('C:\\\\oasis\\\\oasisbusiness-ds\\\\oasisbusiness-ds\\\\1_데이터수집\\\\법정동코드전체.csv')\n",
    "cortar = cortar[cortar['폐지여부\\r\\n']=='존재\\r\\n'] # 존재하는 지역만 남기기\n",
    "lawd_cd_unique = cortar.drop_duplicates('법정동코드')['법정동코드'] # 법정동 코드만 담기 (총 20551개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e833192-cc1b-4da7-81cd-0a151a3edd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. 법정동 API\n",
    "lawd_cd_df = pd.DataFrame()\n",
    "lawd_cd_list = []\n",
    "lawd_cd_unique = []\n",
    "\n",
    "for i in range(1, 22):\n",
    "    \n",
    "    url = 'http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList'\n",
    "    serviceKey = 'C94PKnigawlH2iISVWz1Itw9tVzyuOCbOvKgzCrGOUZWvs3XqrkhH+/ntypJ7kK2P2g16vLYCJif3TNfO1i1KA=='\n",
    "    params = {\n",
    "        'serviceKey' : serviceKey,\n",
    "        'pageNo' : str(i),\n",
    "        'numOfRows' : '1000',\n",
    "        'type' : 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    content = response.text\n",
    "    \n",
    "    # Json List 변환\n",
    "    lawd_cd_df = pd.DataFrame(pd.json_normalize(data = json.loads(content), record_path = 'StanReginCd')['row'][1])\n",
    "    lawd_cd_list = list(lawd_cd_df['locatjumin_cd'].str[:10])\n",
    "    \n",
    "    # 시군구코드 unique하게 남기기\n",
    "    for x in lawd_cd_list:\n",
    "        if x not in lawd_cd_unique:\n",
    "            lawd_cd_unique.append(x)\n",
    "\n",
    "# 시군구 단위 삭제\n",
    "matching = [s for s in lawd_cd_unique if \"00000\" in s]\n",
    "for s in lawd_cd_unique:\n",
    "    if s in matching:\n",
    "        lawd_cd_unique.remove(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1449912-9c19-4b80-888a-f17973cea022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                       | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|██▏                                                                                                            | 1/50 [00:05<04:10,  5.11s/it]\u001b[A\n",
      "  4%|████▍                                                                                                          | 2/50 [00:09<03:36,  4.51s/it]\u001b[A\n",
      "  6%|██████▋                                                                                                        | 3/50 [00:13<03:23,  4.32s/it]\u001b[A\n",
      "  8%|████████▉                                                                                                      | 4/50 [00:17<03:14,  4.23s/it]\u001b[A\n",
      " 10%|███████████                                                                                                    | 5/50 [00:20<02:51,  3.82s/it]\u001b[A\n",
      " 12%|█████████████▎                                                                                                 | 6/50 [00:23<02:37,  3.58s/it]\u001b[A\n",
      " 14%|███████████████▌                                                                                               | 7/50 [00:27<02:41,  3.75s/it]\u001b[A\n",
      " 16%|█████████████████▊                                                                                             | 8/50 [00:30<02:28,  3.53s/it]\u001b[A\n",
      " 18%|███████████████████▉                                                                                           | 9/50 [00:34<02:32,  3.71s/it]\u001b[A\n",
      " 20%|██████████████████████                                                                                        | 10/50 [00:37<02:20,  3.52s/it]\u001b[A\n",
      " 22%|████████████████████████▏                                                                                     | 11/50 [00:42<02:24,  3.70s/it]\u001b[A\n",
      " 24%|██████████████████████████▍                                                                                   | 12/50 [00:45<02:13,  3.51s/it]\u001b[A\n",
      " 26%|████████████████████████████▌                                                                                 | 13/50 [00:51<02:39,  4.30s/it]\u001b[A\n",
      " 28%|██████████████████████████████▊                                                                               | 14/50 [00:56<02:43,  4.54s/it]\u001b[A\n",
      " 30%|█████████████████████████████████                                                                             | 15/50 [00:59<02:23,  4.10s/it]\u001b[A\n",
      " 32%|███████████████████████████████████▏                                                                          | 16/50 [01:03<02:19,  4.11s/it]\u001b[A\n",
      " 34%|█████████████████████████████████████▍                                                                        | 17/50 [01:09<02:35,  4.70s/it]\u001b[A\n",
      " 36%|███████████████████████████████████████▌                                                                      | 18/50 [01:14<02:34,  4.82s/it]\u001b[A\n",
      " 38%|█████████████████████████████████████████▊                                                                    | 19/50 [01:17<02:13,  4.31s/it]\u001b[A\n",
      " 40%|████████████████████████████████████████████                                                                  | 20/50 [01:20<01:58,  3.94s/it]\u001b[A\n",
      " 42%|██████████████████████████████████████████████▏                                                               | 21/50 [01:26<02:04,  4.29s/it]\u001b[A\n",
      " 44%|████████████████████████████████████████████████▍                                                             | 22/50 [01:31<02:07,  4.54s/it]\u001b[A\n",
      " 46%|██████████████████████████████████████████████████▌                                                           | 23/50 [01:34<01:50,  4.11s/it]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████▊                                                         | 24/50 [01:39<01:54,  4.40s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████                                                       | 25/50 [01:44<01:55,  4.61s/it]\u001b[A\n",
      " 52%|█████████████████████████████████████████████████████████▏                                                    | 26/50 [01:49<01:54,  4.76s/it]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████▍                                                  | 27/50 [01:55<01:58,  5.16s/it]\u001b[A\n",
      " 56%|█████████████████████████████████████████████████████████████▌                                                | 28/50 [01:59<01:46,  4.84s/it]\u001b[A\n",
      " 58%|███████████████████████████████████████████████████████████████▊                                              | 29/50 [02:02<01:30,  4.32s/it]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████████████████████                                            | 30/50 [02:05<01:19,  3.95s/it]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████▏                                         | 31/50 [02:10<01:16,  4.00s/it]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████████████████████████▍                                       | 32/50 [02:13<01:07,  3.74s/it]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████████████████████████▌                                     | 33/50 [02:16<01:00,  3.55s/it]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████▊                                   | 34/50 [02:20<00:59,  3.71s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████                                 | 35/50 [02:26<01:06,  4.43s/it]\u001b[A\n",
      " 72%|███████████████████████████████████████████████████████████████████████████████▏                              | 36/50 [02:31<01:04,  4.63s/it]\u001b[A\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████▍                            | 37/50 [02:35<00:58,  4.47s/it]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████▌                          | 38/50 [02:39<00:52,  4.36s/it]\u001b[A\n",
      " 78%|█████████████████████████████████████████████████████████████████████████████████████▊                        | 39/50 [02:42<00:43,  3.99s/it]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████                      | 40/50 [02:47<00:43,  4.32s/it]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████▏                   | 41/50 [02:51<00:35,  3.95s/it]\u001b[A\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████▍                 | 42/50 [02:55<00:32,  4.00s/it]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████▌               | 43/50 [03:01<00:32,  4.63s/it]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████▊             | 44/50 [03:04<00:25,  4.17s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████           | 45/50 [03:08<00:20,  4.15s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 46/50 [03:12<00:16,  4.13s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 47/50 [03:17<00:13,  4.43s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 48/50 [03:21<00:08,  4.33s/it]\u001b[A\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 49/50 [03:26<00:04,  4.56s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [03:33<00:00,  4.26s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████▌                                                       | 1/2 [03:33<03:33, 213.04s/it]\n",
      "  0%|                                                                                                                       | 0/50 [00:03<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [03:36<00:00, 108.06s/it]\n"
     ]
    }
   ],
   "source": [
    "### 2. 전월세 호가 수집\n",
    "# 변수 생성\n",
    "fails = [] # 호가 데이터 없는 법정동\n",
    "info_df = pd.DataFrame()\n",
    "\n",
    "# json to dataframe\n",
    "for i in tqdm(range(0,2)):\n",
    "    \n",
    "    # 다음 페이지 존재 여부 확인\n",
    "    for page in tqdm(range(0,1000)): # 진행상황 확인하고 tqdm 지우기\n",
    "\n",
    "        # url 호출\n",
    "        url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank&page={}'.format(lawd_cd_unique[i],str(i+1))\n",
    "        headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "        time.sleep(random.randrange(3,7))\n",
    "        response = requests.get(url, headers = headers)\n",
    "\n",
    "        # body 태그 선택\n",
    "        items = response.json()['body']\n",
    "\n",
    "        # 다음 페이지 존재 여부 확인\n",
    "        if (response.json()['more'] == True):\n",
    "\n",
    "            try:\n",
    "                # 데이터프레임화\n",
    "                df = pd.DataFrame(items)\n",
    "                info_df = info_df.append(df)\n",
    "\n",
    "            except:\n",
    "                fails.append([i])\n",
    "\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4c719-c107-4f50-bf95-d4ebce8785de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복값 제거\n",
    "if (len(info_df) != len(info_df.drop_duplicates('atclNo'))):\n",
    "    info_df = info_df.drop_duplicates(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4407e258-bc4c-40ca-9634-43355204f7d6",
   "metadata": {},
   "source": [
    "### 돌려놓기 (최종)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ad6b3-4e45-45b0-8fec-cfd3838808ca",
   "metadata": {},
   "source": [
    "* csv ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e1149f-ca54-4956-9676-d247369414ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fake_useragent\n",
      "  Downloading fake_useragent-1.0.1-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\users\\pc\\anaconda3\\envs\\project\\lib\\site-packages (from fake_useragent) (5.7.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\pc\\anaconda3\\envs\\project\\lib\\site-packages (from importlib-resources>=5.0->fake_useragent) (3.8.0)\n",
      "Installing collected packages: fake-useragent\n",
      "Successfully installed fake-useragent-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26618a45-cf82-4e50-8512-f95a2bba1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임포트\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import psycopg2\n",
    "import datetime\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "\n",
    "### 1. 법정동 API\n",
    "lawd_cd_df = pd.DataFrame()\n",
    "lawd_cd_list = []\n",
    "lawd_cd_unique = []\n",
    "\n",
    "for i in range(1, 22):\n",
    "    \n",
    "    url = 'http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList'\n",
    "    serviceKey = 'C94PKnigawlH2iISVWz1Itw9tVzyuOCbOvKgzCrGOUZWvs3XqrkhH+/ntypJ7kK2P2g16vLYCJif3TNfO1i1KA=='\n",
    "    params = {\n",
    "        'serviceKey' : serviceKey,\n",
    "        'pageNo' : str(i),\n",
    "        'numOfRows' : '1000',\n",
    "        'type' : 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    content = response.text\n",
    "    \n",
    "    # Json List 변환\n",
    "    lawd_cd_df = pd.DataFrame(pd.json_normalize(data = json.loads(content), record_path = 'StanReginCd')['row'][1])\n",
    "    lawd_cd_list = list(lawd_cd_df['locatjumin_cd'].str[:10])\n",
    "    \n",
    "    # 시군구코드 unique하게 남기기\n",
    "    for x in lawd_cd_list:\n",
    "        if x not in lawd_cd_unique:\n",
    "            lawd_cd_unique.append(x)\n",
    "\n",
    "# 시군구 단위 삭제 (법정동 단위만 남김 : 총 20,293개)\n",
    "matching = [s for s in lawd_cd_unique if \"00000\" in s]\n",
    "for s in lawd_cd_unique:\n",
    "    if s in matching:\n",
    "        lawd_cd_unique.remove(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072a0e19-ce17-48c5-a1ee-606187a28935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20293"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lawd_cd_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef70b25-5d57-4229-93d8-b8fcdd0eacc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/19855 [00:00<?, ?it/s]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:05<25:38,  5.14s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:15<37:55,  7.63s/it]\u001b[A\n",
      "  0%|                                                                            | 1/19855 [00:55<304:55:28, 55.29s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:08<40:29,  8.13s/it]\u001b[A\n",
      "  0%|                                                                            | 2/19855 [01:03<151:57:38, 27.56s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:30,  9.13s/it]\u001b[A\n",
      "  0%|                                                                            | 3/19855 [01:12<105:34:02, 19.14s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:08<40:35,  8.15s/it]\u001b[A\n",
      "  0%|                                                                             | 4/19855 [01:20<81:38:03, 14.80s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:25,  9.11s/it]\u001b[A\n",
      "  0%|                                                                             | 5/19855 [01:29<70:19:52, 12.76s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:05<25:24,  5.10s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:08<19:26,  3.92s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 3/300 [00:15<25:17,  5.11s/it]\u001b[A\n",
      "  0%|                                                                             | 6/19855 [01:45<75:09:59, 13.63s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:11<55:28, 11.13s/it]\u001b[A\n",
      "  0%|                                                                             | 7/19855 [01:56<70:41:01, 12.82s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:04<20:16,  4.07s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:10<26:06,  5.26s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 3/300 [00:14<23:20,  4.72s/it]\u001b[A\n",
      "  1%|█                                                                                 | 4/300 [00:20<25:57,  5.26s/it]\u001b[A\n",
      "  2%|█▎                                                                                | 5/300 [00:23<22:00,  4.48s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 6/300 [00:27<21:16,  4.34s/it]\u001b[A\n",
      "  2%|█▉                                                                                | 7/300 [00:32<22:23,  4.59s/it]\u001b[A\n",
      "  3%|██▏                                                                               | 8/300 [00:41<25:22,  5.22s/it]\u001b[A\n",
      "  0%|                                                                            | 8/19855 [02:38<121:24:31, 22.02s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:03<15:23,  3.09s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:07<18:12,  3.67s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 3/300 [00:12<21:29,  4.34s/it]\u001b[A\n",
      "  1%|█                                                                                 | 4/300 [00:17<22:52,  4.64s/it]\u001b[A\n",
      "  2%|█▎                                                                                | 5/300 [00:21<21:47,  4.43s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 6/300 [00:26<22:47,  4.65s/it]\u001b[A\n",
      "  2%|█▉                                                                                | 7/300 [00:30<21:47,  4.46s/it]\u001b[A\n",
      "  3%|██▏                                                                               | 8/300 [00:36<24:14,  4.98s/it]\u001b[A\n",
      "  3%|██▍                                                                               | 9/300 [00:42<25:49,  5.32s/it]\u001b[A\n",
      "  3%|██▋                                                                              | 10/300 [00:48<26:50,  5.55s/it]\u001b[A\n",
      "  4%|██▉                                                                              | 11/300 [00:52<24:33,  5.10s/it]\u001b[A\n",
      "  4%|███▏                                                                             | 12/300 [00:58<24:27,  5.10s/it]\u001b[A\n",
      "  4%|███▌                                                                             | 13/300 [01:06<24:19,  5.09s/it]\u001b[A\n",
      "  0%|                                                                            | 9/19855 [03:44<197:26:24, 35.81s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:05<25:20,  5.09s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:08<19:21,  3.90s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 3/300 [00:11<17:25,  3.52s/it]\u001b[A\n",
      "  1%|█                                                                                 | 4/300 [00:17<22:19,  4.53s/it]\u001b[A\n",
      "  2%|█▎                                                                                | 5/300 [00:22<23:12,  4.72s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 6/300 [00:27<23:42,  4.84s/it]\u001b[A\n",
      "  2%|█▉                                                                                | 7/300 [00:32<24:01,  4.92s/it]\u001b[A\n",
      "  3%|██▏                                                                               | 8/300 [00:38<25:43,  5.29s/it]\u001b[A\n",
      "  3%|██▍                                                                               | 9/300 [00:41<22:19,  4.60s/it]\u001b[A\n",
      "  3%|██▋                                                                              | 10/300 [00:47<24:27,  5.06s/it]\u001b[A\n",
      "  4%|██▉                                                                              | 11/300 [00:51<22:55,  4.76s/it]\u001b[A\n",
      "  4%|███▏                                                                             | 12/300 [00:54<20:25,  4.26s/it]\u001b[A\n",
      "  4%|███▌                                                                             | 13/300 [00:58<18:39,  3.90s/it]\u001b[A\n",
      "  5%|███▊                                                                             | 14/300 [01:02<18:50,  3.95s/it]\u001b[A\n",
      "  5%|████                                                                             | 15/300 [01:13<23:12,  4.89s/it]\u001b[A\n",
      "  0%|                                                                           | 10/19855 [04:57<261:11:55, 47.38s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:20,  9.10s/it]\u001b[A\n",
      "  0%|                                                                           | 11/19855 [05:06<196:37:47, 35.67s/it]\n",
      "  0%|                                                                                          | 0/300 [00:06<?, ?it/s]\u001b[A\n",
      "  0%|                                                                           | 12/19855 [05:12<146:58:48, 26.67s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:05<25:20,  5.09s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:08<19:21,  3.90s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 3/300 [00:12<19:42,  3.98s/it]\u001b[A\n",
      "  1%|█                                                                                 | 4/300 [00:15<17:52,  3.62s/it]\u001b[A\n",
      "  2%|█▎                                                                                | 5/300 [00:21<22:10,  4.51s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 6/300 [00:33<27:22,  5.59s/it]\u001b[A\n",
      "  0%|                                                                           | 13/19855 [05:46<158:27:20, 28.75s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:04<20:20,  4.08s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:08<20:18,  4.09s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 3/300 [00:12<20:13,  4.09s/it]\u001b[A\n",
      "  1%|█                                                                                 | 4/300 [00:16<20:08,  4.08s/it]\u001b[A\n",
      "  2%|█▎                                                                                | 5/300 [00:20<20:04,  4.08s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 6/300 [00:23<18:21,  3.75s/it]\u001b[A\n",
      "  2%|█▉                                                                                | 7/300 [00:29<22:00,  4.51s/it]\u001b[A\n",
      "  3%|██▏                                                                               | 8/300 [00:35<24:22,  5.01s/it]\u001b[A\n",
      "  3%|██▍                                                                               | 9/300 [00:41<25:56,  5.35s/it]\u001b[A\n",
      "  3%|██▋                                                                              | 10/300 [00:44<22:26,  4.64s/it]\u001b[A\n",
      "  4%|██▉                                                                              | 11/300 [00:47<20:04,  4.17s/it]\u001b[A\n",
      "  4%|███▏                                                                             | 12/300 [00:53<21:21,  4.45s/it]\u001b[A\n",
      "  4%|███▌                                                                             | 13/300 [00:59<23:38,  4.94s/it]\u001b[A\n",
      "  5%|███▊                                                                             | 14/300 [01:04<23:46,  4.99s/it]\u001b[A\n",
      "  5%|████                                                                             | 15/300 [01:10<25:17,  5.32s/it]\u001b[A\n",
      "  5%|████▎                                                                            | 16/300 [01:16<26:16,  5.55s/it]\u001b[A\n",
      "  6%|████▌                                                                            | 17/300 [01:19<22:39,  4.80s/it]\u001b[A\n",
      "  6%|████▊                                                                            | 18/300 [01:23<21:32,  4.58s/it]\u001b[A\n",
      "  6%|█████▏                                                                           | 19/300 [01:33<23:04,  4.93s/it]\u001b[A\n",
      "  0%|                                                                           | 14/19855 [07:19<266:28:14, 48.35s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:11<55:30, 11.14s/it]\u001b[A\n",
      "  0%|                                                                           | 15/19855 [07:30<204:39:54, 37.14s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:08<40:28,  8.12s/it]\u001b[A\n",
      "  0%|                                                                           | 16/19855 [07:39<156:31:49, 28.40s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:08<40:27,  8.12s/it]\u001b[A\n",
      "  0%|                                                                           | 17/19855 [07:47<122:56:35, 22.31s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:11<55:24, 11.12s/it]\u001b[A\n",
      "  0%|                                                                           | 18/19855 [07:58<104:24:56, 18.95s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:22,  9.10s/it]\u001b[A\n",
      "  0%|                                                                            | 19/19855 [08:07<88:07:08, 15.99s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:10<50:27, 10.13s/it]\u001b[A\n",
      "  0%|                                                                            | 20/19855 [08:17<78:26:16, 14.24s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:05<25:21,  5.09s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:11<28:06,  5.66s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 3/300 [00:20<33:28,  6.76s/it]\u001b[A\n",
      "  0%|                                                                           | 21/19855 [09:18<156:15:06, 28.36s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:08<40:25,  8.11s/it]\u001b[A\n",
      "  0%|                                                                           | 22/19855 [09:27<122:46:20, 22.29s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:07<35:27,  7.12s/it]\u001b[A\n",
      "  0%|                                                                            | 23/19855 [09:34<97:43:31, 17.74s/it]\n",
      "  0%|                                                                                          | 0/300 [00:03<?, ?it/s]\u001b[A\n",
      "  0%|                                                                            | 24/19855 [09:37<73:26:16, 13.33s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:07<35:24,  7.10s/it]\u001b[A\n",
      "  0%|                                                                            | 25/19855 [09:44<63:08:33, 11.46s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:25,  9.12s/it]\u001b[A\n",
      "  0%|                                                                            | 26/19855 [09:53<59:15:43, 10.76s/it]\n",
      "  0%|                                                                                          | 0/300 [00:04<?, ?it/s]\u001b[A\n",
      "  0%|                                                                            | 27/19855 [09:57<48:10:50,  8.75s/it]\n",
      "  0%|                                                                                          | 0/300 [00:05<?, ?it/s]\u001b[A\n",
      "  0%|                                                                            | 28/19855 [10:02<42:05:55,  7.64s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:11<55:28, 11.13s/it]\u001b[A\n",
      "  0%|                                                                            | 29/19855 [10:13<47:53:57,  8.70s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:08<40:24,  8.11s/it]\u001b[A\n",
      "  0%|                                                                            | 30/19855 [10:21<46:57:04,  8.53s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:26,  9.12s/it]\u001b[A\n",
      "  0%|                                                                            | 31/19855 [10:30<47:55:39,  8.70s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:28,  9.12s/it]\u001b[A\n",
      "  0%|                                                                            | 32/19855 [10:40<48:39:46,  8.84s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:24,  9.11s/it]\u001b[A\n",
      "  0%|▏                                                                           | 33/19855 [10:49<49:07:11,  8.92s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:10<50:33, 10.15s/it]\u001b[A\n",
      "  0%|▏                                                                           | 34/19855 [10:59<51:09:28,  9.29s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:07<35:30,  7.12s/it]\u001b[A\n",
      "  0%|▏                                                                           | 35/19855 [11:06<47:35:13,  8.64s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:06<30:30,  6.12s/it]\u001b[A\n",
      "  0%|▏                                                                           | 36/19855 [11:12<43:25:31,  7.89s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:06<30:34,  6.13s/it]\u001b[A\n",
      "  0%|▏                                                                           | 37/19855 [11:18<40:32:08,  7.36s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:09<45:30,  9.13s/it]\u001b[A\n",
      "  0%|▏                                                                           | 38/19855 [11:27<43:29:09,  7.90s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:07<35:29,  7.12s/it]\u001b[A\n",
      "  0%|▏                                                                           | 39/19855 [11:35<42:12:14,  7.67s/it]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                 | 1/300 [00:05<25:17,  5.07s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 2/300 [00:11<27:49,  5.60s/it]\u001b[A\n",
      "  0%|▏                                                                           | 40/19855 [11:46<48:02:38,  8.73s/it]"
     ]
    }
   ],
   "source": [
    "### 2. 전월세 호가 수집\n",
    "# 변수 생성\n",
    "fails = [] # 호가 데이터 없는 법정동\n",
    "noColIdx = [] # 컬럼명 다른 지역 따로 처리\n",
    "\n",
    "# json to dataframe\n",
    "for i in tqdm(range(0,20293)): # 완료 : \n",
    "    \n",
    "    # 36번째에서 막힘\n",
    "    if i % 20 == 0:\n",
    "        time.sleep(random.randrange(40,70))\n",
    "    \n",
    "    # 초기화\n",
    "    info_df = pd.DataFrame()\n",
    "\n",
    "    # 전체 페이지 수집\n",
    "    for page in tqdm(range(0,300)):\n",
    "\n",
    "        # url 호출\n",
    "        url = 'https://m.land.naver.com/cluster/ajax/articleList?itemId=&mapKey=&lgeo=&showR0=&rletTpCd=SG&tradTpCd=A1%3AB1%3AB2&z=14&totCnt=402&cortarNo={}&sort=rank&page={}'.format(lawd_cd_unique[i],str(page+1))\n",
    "        headers = {'user-agent' : ua.ie,'referer' : 'https://m.land.naver.com/'}\n",
    "        time.sleep(random.randrange(3,7))\n",
    "        response = requests.get(url, headers = headers)\n",
    "\n",
    "        # body 태그 선택\n",
    "        items = response.json()['body']\n",
    "\n",
    "        # 다음 페이지 존재 여부 확인\n",
    "        if (len(items) > 0):\n",
    "            try:\n",
    "                # 데이터프레임화\n",
    "                df = pd.DataFrame(items)\n",
    "                info_df = info_df.append(df)\n",
    "            except:\n",
    "                fails.append([i])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 받은 데이터 바로 적재 (언제 막힐지 모르니까 바로바로 적재)\n",
    "    if len(info_df) > 0:\n",
    "        \n",
    "        try:\n",
    "            # 컬럼 정리\n",
    "            info_df = info_df[['atclNo','cortarNo','atclNm','atclStatCd','rletTpCd','uprRletTpCd','rletTpNm','tradTpCd','tradTpNm','vrfcTpCd','flrInfo','prc','rentPrc','spc1','spc2','direction','atclCfmYmd','lat','lng','atclFetrDesc','cpid','cpNm','rltrNm']]\n",
    "            # None 처리\n",
    "            info_df = info_df.fillna(None)\n",
    "            # base_ym\n",
    "            df['base_ym'] = datetime.datetime.now().strftime(\"%Y%m\")\n",
    "            \n",
    "            ### 3. DB INSERT\n",
    "            df = info_df\n",
    "            table = 'm1.asking_price'\n",
    "\n",
    "            # execute_mogrify\n",
    "            def execute_mogrify(conn, df, table, val):\n",
    "                # Create a list of tuples from the dataframe values\n",
    "                tuples = [tuple(x) for x in df.to_numpy()]\n",
    "                # Comma-separated dataframe columns\n",
    "                cols = ','.join(list(df.columns))\n",
    "                # SQL query to execute\n",
    "                cursor = conn.cursor()\n",
    "                values = [cursor.mogrify(val, tup).decode('utf8') for tup in\n",
    "                          tuples]\n",
    "                query = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "\n",
    "                try:\n",
    "                    cursor.execute(query, tuples)\n",
    "                    conn.commit()\n",
    "                except (Exception, psycopg2.DatabaseError) as error:\n",
    "                    print(\"Error: %s\" % error)\n",
    "                    conn.rollback()\n",
    "                    cursor.close()\n",
    "                    return 1\n",
    "                cursor.close()\n",
    "\n",
    "            # values 설정\n",
    "            val = '(' + ('%s,' * len(df.columns))[:-1] + ')'\n",
    "\n",
    "            # insert\n",
    "            for j in range(0, len(df), 10000):\n",
    "\n",
    "                # DB Connect\n",
    "                conn = psycopg2.connect(\n",
    "                    host='redshift-cluster-1.ctvbwnnvbdkl.ap-northeast-2.redshift.amazonaws.com',\n",
    "                    port=5439,\n",
    "                    dbname='dev',\n",
    "                    user='awsuser',\n",
    "                    password='cremaoAdmin1234qwer!!'\n",
    "                )\n",
    "\n",
    "                # 10000개 단위로 나누기\n",
    "                tmp = df[j:j + 10000]\n",
    "\n",
    "                # insert\n",
    "                execute_mogrify(conn, tmp, table, val)\n",
    "                print(datetime.datetime.now(), ' : ', j)\n",
    "                tmp = pd.DataFrame()\n",
    "\n",
    "            # row count\n",
    "            print(len(df))\n",
    "            \n",
    "        except:\n",
    "            noColIdx.append(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
